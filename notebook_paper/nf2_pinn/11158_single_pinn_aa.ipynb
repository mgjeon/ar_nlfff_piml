{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sine(nn.Module):\n",
    "    def __init__(self, w0=1.):\n",
    "        super().__init__()\n",
    "        self.w0 = w0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.w0 * x)\n",
    "\n",
    "\n",
    "class BModel(nn.Module):\n",
    "\n",
    "    def __init__(self, in_coords, out_values, dim):\n",
    "        super().__init__()\n",
    "        self.d_in = nn.Linear(in_coords, dim)\n",
    "        lin = [nn.Linear(dim, dim) for _ in range(8)]\n",
    "        self.linear_layers = nn.ModuleList(lin)\n",
    "        self.d_out = nn.Linear(dim, out_values)\n",
    "        self.activation = Sine()  # torch.tanh\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.d_in(x))\n",
    "        for l in self.linear_layers:\n",
    "            x = self.activation(l(x))\n",
    "        x = self.d_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BModel(3, 3, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_slices = np.load('b.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 256, 256, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_slices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 256, 256, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords = np.stack(np.mgrid[:b_slices.shape[0], :b_slices.shape[1], :b_slices.shape[2]], -1).astype(np.float32)\n",
    "coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = coords.reshape((-1, 3)).astype(np.float32)\n",
    "values = b_slices.reshape((-1, 3)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33554432, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33554432, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 256, 256, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cube_shape = b_slices.shape\n",
    "cube_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube_shape = np.array([[0, cube_shape[0] - 1], [0, cube_shape[1] - 1], [0, cube_shape[2] - 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path, b_norm, spatial_norm, boundary_batch_coords, random_batch_coords):\n",
    "        self.data_path = data_path\n",
    "        self.b_norm = b_norm\n",
    "        self.spatial_norm = spatial_norm\n",
    "        self.boundary_batch_coords = int(boundary_batch_coords)\n",
    "        self.random_batch_coords = int(random_batch_coords)\n",
    "        self.float_tensor = torch.FloatTensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        b_slices = np.load(self.data_path)\n",
    "\n",
    "        coords = np.stack(np.mgrid[:b_slices.shape[0], :b_slices.shape[1], :b_slices.shape[2]], -1).astype(np.float32)\n",
    "        coords = coords.reshape((-1, 3)).astype(np.float32)\n",
    "        values = b_slices.reshape((-1, 3)).astype(np.float32)\n",
    "\n",
    "        coords = coords / self.spatial_norm\n",
    "        values = values / self.b_norm\n",
    "\n",
    "        cube_shape = b_slices.shape\n",
    "        cube_shape = np.array([[0, cube_shape[0] - 1], [0, cube_shape[1] - 1], [0, cube_shape[2] - 1]])\n",
    "\n",
    "        random_coords = self.float_tensor(self.random_batch_coords, 3).uniform_()\n",
    "        random_coords[:, 0] = (random_coords[:, 0] * (cube_shape[0, 1] - cube_shape[0, 0]) + cube_shape[0, 0])\n",
    "        random_coords[:, 1] = (random_coords[:, 1] * (cube_shape[1, 1] - cube_shape[1, 0]) + cube_shape[1, 0])\n",
    "        random_coords[:, 2] = (random_coords[:, 2] * (cube_shape[2, 1] - cube_shape[2, 0]) + cube_shape[2, 0])\n",
    "        random_coords = random_coords / self.spatial_norm\n",
    "\n",
    "        #--- pick one data\n",
    "        r = np.random.choice(coords.shape[0], self.boundary_batch_coords)\n",
    "        coords = coords[r]\n",
    "        values = values[r]\n",
    "        \n",
    "        samples = {'random_coords': random_coords,\n",
    "                   'coords': coords,\n",
    "                   'values': values}\n",
    "\n",
    "        return samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset('b.npy', 2500, 255, 100, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = None\n",
    "num_workers = 4\n",
    "num_samples = 200\n",
    "don_loader = DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True,\n",
    "                        sampler=RandomSampler(dataset, replacement=True, num_samples=num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(don_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_coords = batch['random_coords'].to(device)\n",
    "coords = batch['coords'].to(device)\n",
    "values = batch['values'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3])\n",
      "torch.Size([100, 3])\n",
      "torch.Size([100, 3])\n"
     ]
    }
   ],
   "source": [
    "print(random_coords.shape)\n",
    "print(coords.shape)\n",
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobian(output, coords):\n",
    "    jac_matrix = [torch.autograd.grad(output[..., i], coords,\n",
    "                                      grad_outputs=torch.ones_like(output[..., i]).to(output),\n",
    "                                      retain_graph=True, create_graph=True, allow_unused=True)[0]\n",
    "                  for i in range(output.shape[-1])]\n",
    "    jac_matrix = torch.stack(jac_matrix, dim=-1)\n",
    "    return jac_matrix\n",
    "\n",
    "\n",
    "def calculate_pde_loss(b, coords):\n",
    "    jac_matrix = jacobian(b, coords)\n",
    "    dBx_dx = jac_matrix[..., 0, 0]\n",
    "    dBy_dx = jac_matrix[..., 1, 0]\n",
    "    dBz_dx = jac_matrix[..., 2, 0]\n",
    "    dBx_dy = jac_matrix[..., 0, 1]\n",
    "    dBy_dy = jac_matrix[..., 1, 1]\n",
    "    dBz_dy = jac_matrix[..., 2, 1]\n",
    "    dBx_dz = jac_matrix[..., 0, 2]\n",
    "    dBy_dz = jac_matrix[..., 1, 2]\n",
    "    dBz_dz = jac_matrix[..., 2, 2]\n",
    "    #\n",
    "    curl_x = dBz_dy - dBy_dz\n",
    "    curl_y = dBx_dz - dBz_dx\n",
    "    curl_z = dBy_dx - dBx_dy\n",
    "    #\n",
    "    j = torch.stack([curl_x, curl_y, curl_z], -1)\n",
    "    #\n",
    "    jxb = torch.cross(j, b, -1)\n",
    "    loss_ff = torch.sum(jxb ** 2, dim=-1) / (torch.sum(b ** 2, dim=-1) + 1e-7)\n",
    "\n",
    "    loss_div = (dBx_dx + dBy_dy + dBz_dz) ** 2\n",
    "    return loss_div, loss_ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_start = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_loader = tqdm(don_loader, desc='Train')\n",
    "\n",
    "best_loss = np.inf\n",
    "\n",
    "model = model.train()\n",
    "\n",
    "for idx, batch in enumerate(tqdm_loader):\n",
    "\n",
    "    branch_input = batch['branch_input']\n",
    "\n",
    "    coords = batch['coords']\n",
    "    coords.requires_grad = True\n",
    "    b_slices = batch['values'].to(device)\n",
    "\n",
    "    random_coords = batch['random_coords']\n",
    "    random_coords.requires_grad = True\n",
    "\n",
    "    n_boundary_coords = coords.shape[1]\n",
    "    coords = torch.concatenate([coords, random_coords], 1)\n",
    "\n",
    "    branch_input = branch_input.to(device)\n",
    "    coords = coords.to(device)\n",
    "\n",
    "    b = model(branch_input, coords)\n",
    "\n",
    "    b_pred = b[:, :n_boundary_coords, :]\n",
    "    loss_bc = torch.clip(torch.abs(b_pred - b_slices), 0)\n",
    "    loss_bc = torch.mean(torch.nansum(loss_bc.pow(2), -1))\n",
    "    \n",
    "    loss_div, loss_ff = calculate_pde_loss(b, coords)\n",
    "    loss_div, loss_ff = loss_div.mean(), loss_ff.mean()\n",
    "\n",
    "    loss = lambda_b * loss_bc + \\\n",
    "           lambda_div * loss_div + \\\n",
    "           lambda_ff * loss_ff\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    tqdm_loader.set_description(f\"Loss {loss.item():.4f} bc {loss_bc.item():.4f} div {loss_div.item():.4f} ff {loss_ff.item():.4f}\")\n",
    "\n",
    "    torch.save({'idx': idx, \n",
    "                'model_state_dict': model.state_dict(), \n",
    "                'optimizer_state_dict': optimizer.state_dict()}, \n",
    "                \"last.pt\")\n",
    "\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                'spatial_norm':spatial_norm,\n",
    "                'b_norm':b_norm,\n",
    "                'cube_shape':cube_shape}, \"model_last.pt\")\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        torch.save({'idx': idx, \n",
    "                    'model_state_dict': model.state_dict(), \n",
    "                    'optimizer_state_dict': optimizer.state_dict()}, \n",
    "                    \"best.pt\")\n",
    "        torch.save({'model_state_dict': model.state_dict(),\n",
    "                    'spatial_norm':spatial_norm,\n",
    "                    'b_norm':b_norm,\n",
    "                    'cube_shape':cube_shape}, \"model_best.pt\")\n",
    "        best_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtmag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
