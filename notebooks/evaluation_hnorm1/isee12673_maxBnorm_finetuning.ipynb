{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "from neuralop.models import UNO\n",
    "from magplot.base import create_mesh, mag_plotter\n",
    "import pyvista as pv\n",
    "pv.start_xvfb()\n",
    "pv.set_jupyter_backend('static')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from rtmag.test.eval_plot import plot_sample\n",
    "\n",
    "from rtmag.test.eval import evaluate\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import gc\n",
    "from rtmag.train.diff_torch_batch import curl, divergence\n",
    "from torchmetrics.regression import ConcordanceCorrCoef, MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_path = Path(\"/home/usr/workspace/base/uno_pi_cc_hnorm_1_unit_aug_ccc_square\")\n",
    "checkpoint = torch.load(meta_path / \"best_model.pt\", map_location=device)\n",
    "\n",
    "args = argparse.Namespace()\n",
    "info = np.load(meta_path / 'args.npy', allow_pickle=True).item()\n",
    "for key, value in info.items():\n",
    "        args.__dict__[key] = value\n",
    "\n",
    "# b_norm = args.data[\"b_norm\"]\n",
    "\n",
    "model = UNO(\n",
    "        hidden_channels = args.model[\"hidden_channels\"],\n",
    "        in_channels = args.model[\"in_channels\"],\n",
    "        out_channels = args.model[\"out_channels\"],\n",
    "        lifting_channels = args.model[\"lifting_channels\"],\n",
    "        projection_channels = args.model[\"projection_channels\"],\n",
    "        n_layers = args.model[\"n_layers\"],\n",
    "\n",
    "        factorization = args.model[\"factorization\"],\n",
    "        implementation = args.model[\"implementation\"],\n",
    "        rank = args.model[\"rank\"],\n",
    "\n",
    "        uno_n_modes = args.model[\"uno_n_modes\"], \n",
    "        uno_out_channels = args.model[\"uno_out_channels\"],\n",
    "        uno_scalings = args.model[\"uno_scalings\"],\n",
    "    ).to(device)\n",
    "\n",
    "checkpoint = torch.load(meta_path / 'best_model.pt')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_12673_20170906_083600.npz\n",
      "label_12673_20170906_083600.npz\n"
     ]
    }
   ],
   "source": [
    "idx = 239\n",
    "\n",
    "data_path = Path('/mnt/f/isee_dataset/12673/input/').glob('*.npz')\n",
    "data_path = sorted(data_path)\n",
    "\n",
    "label_path = Path('/mnt/f/isee_dataset/12673/label/').glob('*.npz')\n",
    "label_path = sorted(label_path)\n",
    "\n",
    "print(data_path[idx].name)\n",
    "print(label_path[idx].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.load(data_path[idx])\n",
    "model_input = torch.from_numpy(inputs['input'])[None, ...]\n",
    "\n",
    "b_norm = torch.max(torch.abs(model_input)).item()\n",
    "# [batch_size, 3, 513, 257, 1]\n",
    "model_input = model_input[:, :, :-1, :-1, :] / b_norm # remove duplicated periodic boundary\n",
    "model_input = model_input.to(device)\n",
    "model_input = torch.permute(model_input, (0, 4, 3, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256, 512, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = model(model_input).detach()\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:0, loss:0.00119064, mse:0, bc:0, ff:8.8e-06, div:3.1e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/200 [00:03<10:39,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter:1, loss:0.00171149, mse:0.0052, bc:5e-05, ff:8e-06, div:3.6e-06\n"
     ]
    }
   ],
   "source": [
    "model = model.train()\n",
    "optimizer = Adam(model.parameters(), lr=args.training['learning_late'])\n",
    "\n",
    "with tqdm(range(200)) as tqdm_loader_train:\n",
    "        for iteration in tqdm_loader_train:\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                loss = {}\n",
    "                # [b, z, y, x, 3] \n",
    "                outputs = model(model_input).to(device)\n",
    "\n",
    "                # [b, z, y, x, 3] -> [b, z, ...]\n",
    "                opts = torch.flatten(outputs, start_dim=2)\n",
    "                lbls = torch.flatten(labels, start_dim=2)\n",
    "\n",
    "                # [b, z, ...] -> [b, ..., z]\n",
    "                opts = torch.permute(opts, (0, 2, 1))\n",
    "                lbls = torch.permute(lbls, (0, 2, 1))\n",
    "\n",
    "                # mse loss\n",
    "                mse = MeanSquaredError().to(device)\n",
    "                loss_mse = torch.mean(mse(opts.flatten(), lbls.flatten()))\n",
    "                loss['mse'] = loss_mse\n",
    "\n",
    "                # ccc loss\n",
    "                # ccc = ConcordanceCorrCoef(num_outputs=opts.shape[-1]).to(device)\n",
    "                # loss_ccc = 0.0\n",
    "                # if args.training.get('ccc_square', False):\n",
    "                #         for i in range(opts.shape[0]):\n",
    "                #                 loss_ccc += torch.mean(torch.square(1.0 - ccc(opts[i], lbls[i])))\n",
    "                # else:\n",
    "                #         for i in range(opts.shape[0]):\n",
    "                #                 loss_ccc += torch.mean(torch.abs(1.0 - ccc(opts[i], lbls[i])))\n",
    "                # loss_ccc /= opts.shape[0]\n",
    "                # loss['ccc'] = loss_ccc\n",
    "                \n",
    "                # [b, z, y, x, 3] -> [b, x, y, z, 3]\n",
    "                b = torch.permute(outputs, (0, 3, 2, 1, 4))\n",
    "                B = torch.permute(labels, (0, 3, 2, 1, 4))\n",
    "\n",
    "\n",
    "                # unnormalization\n",
    "                if args.data[\"dataset_name\"] == \"Hnorm_Square_Unit_Aug\":\n",
    "                        divisor = (1 / np.arange(1, b.shape[2] + 1)**2 ).reshape(1, 1, -1, 1).astype(np.float32)\n",
    "                else:\n",
    "                        divisor = (1 / np.arange(1, b.shape[2] + 1)).reshape(1, 1, -1, 1).astype(np.float32)\n",
    "                        \n",
    "                divisor = torch.from_numpy(divisor).to(device)\n",
    "                b = b * divisor\n",
    "                B = B * divisor\n",
    "                \n",
    "                # boundary condition loss\n",
    "                loss_bc = 0.0\n",
    "                # bottom (z=0)\n",
    "                loss_bc += torch.mean(torch.square(b[:, :, :, 0, :] - B[:, :, :, 0, :]))\n",
    "                loss['bc'] = loss_bc\n",
    "\n",
    "                dx = torch.from_numpy(np.array([1.0]).astype(np.float32)).reshape(-1, 1)[None, ...].to(device)\n",
    "                dy = torch.from_numpy(np.array([1.0]).astype(np.float32)).reshape(-1, 1)[None, ...].to(device)\n",
    "                dz = torch.from_numpy(np.array([1.0]).astype(np.float32)).reshape(-1, 1)[None, ...].to(device)\n",
    "\n",
    "                # force-free loss\n",
    "                bx, by, bz = b[..., 0], b[..., 1], b[..., 2]\n",
    "                jx, jy, jz = curl(bx, by, bz, dx, dy, dz)\n",
    "                b = torch.stack([bx, by, bz], -1)\n",
    "                j = torch.stack([jx, jy, jz], -1)\n",
    "\n",
    "                jxb = torch.cross(j, b, -1)\n",
    "                loss_ff = (jxb**2).sum(-1) / ((b**2).sum(-1) + 1e-7)\n",
    "                loss_ff = torch.mean(loss_ff)\n",
    "                loss['ff'] = loss_ff\n",
    "\n",
    "                # divergence-less loss\n",
    "                div_b = divergence(bx, by, bz, dx, dy, dz)\n",
    "                loss_div = torch.mean(torch.square(div_b))\n",
    "                loss['div'] = loss_div\n",
    "\n",
    "\n",
    "                los = 0.01*args.training['w_mse']*loss['mse'] \\\n",
    "                + args.training['w_bc']*loss['bc'] \\\n",
    "                + 100*args.training['w_ff']*loss['ff'] \\\n",
    "                + 100*args.training['w_div']*loss['div'] \\\n",
    "                \n",
    "                print(f\"iter:{iteration}, loss:{los.item():2g}, mse:{loss_mse.item():.2g}, bc:{loss_bc.item():.2g}, ff:{loss_ff.item():.2g}, div:{loss_div.item():.2g}\")\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                los.backward()\n",
    "                optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model(model_input)\n",
    "# [512, 256, 256, 3]\n",
    "b = model_output.detach().cpu().numpy().transpose(0, 3, 2, 1, 4)[0]\n",
    "divi = (b_norm / np.arange(1, b.shape[2] + 1)).reshape(1, 1, -1, 1)\n",
    "b = b * divi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.load(label_path[idx])[\"label\"][:, :-1, :-1, :-1]\n",
    "B = B.transpose(1, 2, 3, 0)\n",
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(b, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin=-2500\n",
    "vmax=2500\n",
    "i_siz=b.shape[0] / 2\n",
    "j_siz=b.shape[1] / 2\n",
    "i_res=16\n",
    "j_res=16\n",
    "window_size=(1200, 800)\n",
    "zoom=1.5\n",
    "max_time=10000\n",
    "camera_position = 'xy'\n",
    "b_title = ''\n",
    "title_fontsize = 10\n",
    "\n",
    "bx = b[..., 0]\n",
    "by = b[..., 1]\n",
    "bz = b[..., 2]\n",
    "mesh = create_mesh(bx, by, bz)\n",
    "b_plot = mag_plotter(mesh)\n",
    "b_tube, b_bottom, b_dargs = b_plot.create_mesh(i_siz=i_siz, j_siz=j_siz, i_resolution=i_res, j_resolution=j_res, vmin=vmin, vmax=vmax, max_time=max_time)\n",
    "\n",
    "\n",
    "p = pv.Plotter(off_screen=False, window_size=window_size)\n",
    "p.add_mesh(b_plot.grid.outline())\n",
    "p.add_mesh(b_bottom, cmap='gray', **b_dargs)\n",
    "p.add_mesh(b_tube, lighting=False, color='blue')\n",
    "p.camera_position = camera_position\n",
    "p.add_title(b_title, font_size=title_fontsize)\n",
    "p.camera.zoom(zoom)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin=-2500\n",
    "vmax=2500\n",
    "i_siz=B.shape[0] / 2\n",
    "j_siz=B.shape[1] / 2\n",
    "i_res=16\n",
    "j_res=16\n",
    "window_size=(1200, 800)\n",
    "zoom=1.5\n",
    "max_time=10000\n",
    "camera_position = 'xy'\n",
    "b_title = ''\n",
    "title_fontsize = 10\n",
    "\n",
    "bx = B[..., 0]\n",
    "by = B[..., 1]\n",
    "bz = B[..., 2]\n",
    "mesh = create_mesh(bx, by, bz)\n",
    "b_plot = mag_plotter(mesh)\n",
    "b_tube, b_bottom, b_dargs = b_plot.create_mesh(i_siz=i_siz, j_siz=j_siz, i_resolution=i_res, j_resolution=j_res, vmin=vmin, vmax=vmax, max_time=max_time)\n",
    "\n",
    "\n",
    "p = pv.Plotter(off_screen=False, window_size=window_size)\n",
    "p.add_mesh(b_plot.grid.outline())\n",
    "p.add_mesh(b_bottom, cmap='gray', **b_dargs)\n",
    "p.add_mesh(b_tube, lighting=False, color='blue')\n",
    "p.camera_position = camera_position\n",
    "p.add_title(b_title, font_size=title_fontsize)\n",
    "p.camera.zoom(zoom)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(b, B, v_mm=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtmag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
